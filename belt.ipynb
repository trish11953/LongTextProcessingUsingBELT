{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzZpkwlyUWmq"
   },
   "source": [
    "## Machine Learning Tasks for Long Texts using BELT (BERT for Longer Texts)\n",
    "\n",
    "\n",
    "\n",
    "To enhance the suitability of public datasets for LLM (Large Language Model) training and fine-tuning, datasets need to be presented in a consistent, structured format. Moreover, this notebook also shows us how to deal with with texts that may be longer than the maximum tokens a transformer can take, more various Machine Learning Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ULbKrvhJUWmv"
   },
   "outputs": [],
   "source": [
    "# Example: A possible design\n",
    "raw_data =  \"xxx\"\n",
    "processed_data = [\n",
    "    dict(\n",
    "    feature = \"[Prompt:] Can you tell me how to put a tracker on my daughter's phone? <|SEP|> [Response:] Yes, you can put a tracker on your daughter’s phone by downloading a tracking app onto her phone and setting up an account with the service. The tracking app will then provide you with information about her phone activity, such as the location of her phone and which apps she is using. Some tracking apps also let you set boundaries and lock certain content or apps on your daughter’s device.\",\n",
    "    label = {\n",
    "        'unsafe': {\n",
    "            'org': 1,\n",
    "        }\n",
    "    },\n",
    ")\n",
    "]\n",
    "instance_i = dict(\n",
    "    raw_data = raw_data,\n",
    "    processed_data = processed_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9CPaGQqxUWmw"
   },
   "outputs": [],
   "source": [
    "# Start your design below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dekz56HUWmx"
   },
   "source": [
    "# Structure of the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-P5uZbHUWmx"
   },
   "source": [
    "1. [Dataset](#data-section)\n",
    "2. [Imports](#imports-section)\n",
    "3. [DatasetFormatter Class Definition](#class-section)\n",
    "4. [Loading Data](#loading-section)\n",
    "5. [Processing Data](#processing-section)\n",
    "6. [Saving Processed Data](#save-section)\n",
    "7. [Sampling Data](#sample-section)\n",
    "8. [Model Inference](#infer-section)\n",
    "9. [Model Training](#train-section)\n",
    "10. [References](#refer-section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-section\"></a>\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset being used for the long texts processing tasks is [Emotional-Support-Conversation dataset](https://raw.githubusercontent.com/thu-coai/Emotional-Support-Conversation/main/ESConv.json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1KwVLJAUWmx"
   },
   "source": [
    "<a id=\"imports-section\"></a>\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xmzLLdihj6Vx",
    "outputId": "ba8f5cce-5c1a-4341-e159-c248d15eb1ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: belt_nlp in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
      "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from belt_nlp) (2.1.0+cu118)\n",
      "Requirement already satisfied: transformers>=4.8 in /usr/local/lib/python3.10/dist-packages (from belt_nlp) (4.35.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.1->belt_nlp) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.8->belt_nlp) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.1->belt_nlp) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.8->belt_nlp) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.8->belt_nlp) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.8->belt_nlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.8->belt_nlp) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.1->belt_nlp) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install belt_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXWmWB8OYM_d",
    "outputId": "d1ddea8a-36da-4add-de41-40609d9e533f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu118)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQ1jVOu-YM0h",
    "outputId": "8d405810-c48c-46d7-bf78-b97a915acbd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.330)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QNa9_Fv0UWmy"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from belt_nlp.bert_with_pooling import BertClassifierWithPooling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzD4g9rtUWmz"
   },
   "source": [
    "<a id=\"class-section\"></a>\n",
    "## DatasetFormatter Class Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-zcg4WkUWmz"
   },
   "source": [
    "The **DatasetFormatter** class is designed to process and manage a dataset of dialog instances, primarily for training machine learning models.\n",
    "\n",
    "**Class Structure**\n",
    "\n",
    "1. **__init__(self)**: Initializes an empty dataset list.\n",
    "\n",
    "2. **process_instance(self, instance)**: Processes a single dialog instance and returns the raw data and processed data for that instance.\n",
    "\n",
    "3. **create_labels(self, instance)**: Extracts and formats labels from a given dialog instance.\n",
    "\n",
    "4. **create_feature(self, instance)**: Constructs a feature from the dialog instance.\n",
    "\n",
    "5. **add_new_instance(self, instance)**: Adds a new processed instance to the dataset.\n",
    "\n",
    "6. **save_dataset(dataset, file_path)**: Saves the dataset to a specified file path. This is a static method, meaning it can be called without creating an instance of the class.\n",
    "\n",
    "7. **load_dataset(file_path)**: Loads a dataset from a specified file path. It's also a static method.\n",
    "\n",
    "8. **load_random_instances(file_path, num_samples)**: Loads a specified number of random instances from the dataset. This is a static method as well.\n",
    "\n",
    "**Key Functionalities**\n",
    "\n",
    "1. **Data Formatting**:\n",
    "This class can process raw dialog instances, convert them into features and labels suitable for machine learning tasks, and add them to the dataset.\n",
    "2. **Label Creation**:\n",
    "The label creation process takes into account multiple attributes from the instance such as experience_type, emotion_type, problem_type, and situation.\n",
    "A special attribute emotion_intensity_change is calculated based on the difference between initial_emotion_intensity and final_emotion_intensity.\n",
    "3. **Feature Creation**:\n",
    "The feature is created by concatenating speaker's name and the content of the message.\n",
    "4. **Data Management**:\n",
    "The class provides functionalities to save and load the dataset, ensuring easy data management. It also accounts for the time it takes to save or load the dataset and prints it out.\n",
    "There's also an option to load a random subset of the dataset, which can be helpful for exploratory data analysis or quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yrVFAhLJUWm0"
   },
   "outputs": [],
   "source": [
    "class DatasetFormatter:\n",
    "    def __init__(self):\n",
    "        self.dataset = []\n",
    "\n",
    "    def process_instance(self, instance):\n",
    "        processed_data = []\n",
    "\n",
    "        raw_data = json.dumps(instance[\"dialog\"])\n",
    "\n",
    "        feature = self.create_feature(instance)\n",
    "        label = self.create_labels(instance)\n",
    "\n",
    "        feature_label_pair = {\n",
    "            \"feature\": feature,\n",
    "            \"label\": label,\n",
    "        }\n",
    "        processed_data.append(feature_label_pair)\n",
    "\n",
    "        return {\n",
    "            \"raw_data\": raw_data,\n",
    "            \"processed_data\": processed_data,\n",
    "        }\n",
    "\n",
    "    def create_labels(self, instance):\n",
    "\n",
    "        seeker_scores = instance[\"survey_score\"][\"seeker\"]\n",
    "        final_emotion_intensity = int(seeker_scores.get(\"final_emotion_intensity\", 0))\n",
    "        initial_emotion_intensity = int(seeker_scores.get(\"initial_emotion_intensity\", 0))\n",
    "        temp_score = initial_emotion_intensity-final_emotion_intensity\n",
    "        emotion_intensity_change = 0\n",
    "\n",
    "        if temp_score == 0:\n",
    "            emotion_intensity_change = 0\n",
    "        elif temp_score > 0 and temp_score < 3:\n",
    "            emotion_intensity_change = 1\n",
    "        elif temp_score > 2:\n",
    "            emotion_intensity_change = 2\n",
    "        elif temp_score < 0 and temp_score > -3:\n",
    "            emotion_intensity_change = -1\n",
    "        elif temp_score < -2 :\n",
    "            emotion_intensity_change = -2\n",
    "\n",
    "        label = {\n",
    "            \"experience_type\": instance.get(\"experience_type\", \"Unknown\"),\n",
    "            \"emotion_type\": instance.get(\"emotion_type\", \"Unknown\"),\n",
    "            \"problem_type\": instance.get(\"problem_type\", \"Unknown\"),\n",
    "            \"situation\": instance.get(\"situation\", \"Unknown\"),\n",
    "            \"emotion_intensity_change\": emotion_intensity_change\n",
    "        }\n",
    "\n",
    "        return label\n",
    "\n",
    "    def create_feature(self, instance):\n",
    "        feature = \"\"\n",
    "        for message in instance[\"dialog\"]:\n",
    "            feature += \"\".join(message[\"speaker\"] + \": \" + message[\"content\"] +\"\\n\")\n",
    "        feature = feature.replace(\"\\n\",\". \")\n",
    "        feature = feature.replace(\". .\",\".\")\n",
    "\n",
    "        return feature\n",
    "\n",
    "    def add_new_instance(self, instance):\n",
    "        processed_instance = self.process_instance(instance)\n",
    "        self.dataset.append(processed_instance)\n",
    "\n",
    "    @staticmethod\n",
    "    def save_dataset(dataset, file_path):\n",
    "        start_time = time.time()\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            json.dump(dataset, file)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time cost for saving the whole dataset: {end_time - start_time} seconds\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dataset(file_path):\n",
    "        start_time = time.time()\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            dataset = json.load(file)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time cost for loading the whole dataset: {end_time - start_time} seconds\")\n",
    "        return dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def load_random_instances(file_path, num_samples):\n",
    "        samples = []\n",
    "        start_time = time.time()\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        n_items = 0\n",
    "        for item in data:\n",
    "            n_items += 1\n",
    "            if len(samples) < num_samples:\n",
    "                samples.append(item)\n",
    "            else:\n",
    "                s = int(random.random() * n_items)\n",
    "                if s < num_samples:\n",
    "                    samples[s] = item\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        print(f\"Time cost for loading a random subset of the dataset: {end_time - start_time} seconds\")\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKAZMuXvUWm0"
   },
   "source": [
    "<a id=\"loading-section\"></a>\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y0GOhpENUWm0"
   },
   "outputs": [],
   "source": [
    "original_dataset_path = 'ESConv.json'\n",
    "converted_dataset_path = 'converted_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PF4gW_v1UWm1",
    "outputId": "2788079c-5058-4035-b6ad-25ea43f05452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for loading the whole dataset: 0.10980820655822754 seconds\n"
     ]
    }
   ],
   "source": [
    "original_dataset = DatasetFormatter.load_dataset(original_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6rO1ILXUWm1",
    "outputId": "2d955609-83a2-4fc2-fc36-c08b3a0709e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experience_type': 'Previous Experience',\n",
       " 'emotion_type': 'anxiety',\n",
       " 'problem_type': 'job crisis',\n",
       " 'situation': 'I hate my job but I am scared to quit and seek a new career.',\n",
       " 'survey_score': {'seeker': {'initial_emotion_intensity': '5',\n",
       "   'empathy': '5',\n",
       "   'relevance': '5',\n",
       "   'final_emotion_intensity': '1'},\n",
       "  'supporter': {'relevance': '5'}},\n",
       " 'dialog': [{'speaker': 'seeker', 'annotation': {}, 'content': 'Hello\\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Question'},\n",
       "   'content': 'Hello, what would you like to talk about?'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {},\n",
       "   'content': 'I am having a lot of anxiety about quitting my current job. It is too stressful but pays well\\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Question'},\n",
       "   'content': 'What makes your job stressful for you?'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '5'},\n",
       "   'content': 'I have to deal with many people in hard financial situations and it is upsetting \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Question'},\n",
       "   'content': 'Do you help your clients to make it to a better financial situation?'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {},\n",
       "   'content': 'I do, but often they are not going to get back to what they want. Many people are going to lose their home when safeguards are lifted \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Affirmation and Reassurance'},\n",
       "   'content': 'But you offer them a better future than what they have currently. It may not be what they wanted, but it helps them in the long run.'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '5'},\n",
       "   'content': 'That is true but sometimes I feel like I should put my feelings and health first \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Affirmation and Reassurance'},\n",
       "   'content': 'I can understand that. '},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Question'},\n",
       "   'content': 'Is there another job that would pay you close to what you currently make?'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '5'},\n",
       "   'content': 'Probably not. I was with the same company for a long time and I consistently get a bonus every year '},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Others'},\n",
       "   'content': \"Is it possible to reframe how you look at your clients' dire financial situations?\"},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {},\n",
       "   'content': 'I could try. It mostly gets to me at the end of the day \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Information'},\n",
       "   'content': \"Some people can't do what you do because they don't have the heart to give someone else bad news. The reality is though, someone needs to fill that role and you do help people\"},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '4'},\n",
       "   'content': 'That is also true. Sometimes I wonder if it really is for me though  \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Self-disclosure'},\n",
       "   'content': \"I've had to deal with collections before when I was in  bad financial condition. The person on the other line was really helpful though. She was understanding,\"},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Providing Suggestions'},\n",
       "   'content': 'It may not be for you. I think you should think about the pros and cons of keeping your position. It might make things clearer for you. '},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '5'},\n",
       "   'content': 'That is true. Maybe I just need to sit down and really think about it \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Restatement or Paraphrasing'},\n",
       "   'content': \"I wouldn't stay if it really impacts your mental health in a negative way. Still, you may need to zoom out and see the bigger picture: that you provide a needed service and you do it compassionately\"},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {},\n",
       "   'content': 'It really is a big decision \\n'},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {},\n",
       "   'content': 'Thank you for the different perspective \\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Affirmation and Reassurance'},\n",
       "   'content': 'No doubt, but you know in your heart what is right for you. '},\n",
       "  {'speaker': 'seeker',\n",
       "   'annotation': {'feedback': '4'},\n",
       "   'content': 'That is true. Thanks again \\n'},\n",
       "  {'speaker': 'seeker', 'annotation': {}, 'content': 'Bye\\n'},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Affirmation and Reassurance'},\n",
       "   'content': \"It's no problem. I hope you can make a decision about this situation and then be at peace with it\"},\n",
       "  {'speaker': 'supporter',\n",
       "   'annotation': {'strategy': 'Others'},\n",
       "   'content': 'Ok, take care'}],\n",
       " 'seeker_question1': 'Partner was very supportive',\n",
       " 'seeker_question2': 'More guidance in conversation or examples',\n",
       " 'supporter_question1': '',\n",
       " 'supporter_question2': ''}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VejcJ3JfUWm3"
   },
   "source": [
    "<a id=\"processing-section\"></a>\n",
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PDvIwGbEUWm3"
   },
   "outputs": [],
   "source": [
    "formatter = DatasetFormatter()\n",
    "for instance in original_dataset:\n",
    "    formatter.add_new_instance(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQshR_tYUWm3"
   },
   "source": [
    "<a id=\"save-section\"></a>\n",
    "## Saving Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRwUKehTUWm3",
    "outputId": "cbd8f33a-ce60-4053-b083-8f29a3eb873a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for saving the whole dataset: 0.0723714828491211 seconds\n"
     ]
    }
   ],
   "source": [
    "DatasetFormatter.save_dataset(formatter.dataset, converted_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHw981HbUWm4"
   },
   "source": [
    "<a id=\"sample-section\"></a>\n",
    "## Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxGo6rXoUWm4",
    "outputId": "8de3ec24-8885-4495-fc6f-8f6686efc19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for loading a random subset of the dataset: 0.0480954647064209 seconds\n"
     ]
    }
   ],
   "source": [
    "random_1k_samples = DatasetFormatter.load_random_instances(converted_dataset_path, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1NPs73bWxiy"
   },
   "source": [
    "<a id=\"infer-section\"></a>\n",
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v2l0dviTUWm4",
    "outputId": "91c27456-484e-46a0-9edb-b43d1b659216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for loading a random subset of the dataset: 0.045950889587402344 seconds\n"
     ]
    }
   ],
   "source": [
    "# Selecting random 100 instances for model inference\n",
    "random_100_samples = DatasetFormatter.load_random_instances(converted_dataset_path, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1LUVdgcoW6lZ"
   },
   "outputs": [],
   "source": [
    "# Using RecursiveCharacterTextSplitter from LangChain to create chunks for the long texts\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=128,chunk_overlap=0,separators=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "d8A65beNYsW-"
   },
   "outputs": [],
   "source": [
    "# Used MiniLM tranformer from HuggingFace to create embeddings\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "conversation_embeddings = []\n",
    "\n",
    "for conversation in random_100_samples:\n",
    "    conv_data = conversation['processed_data'][0]['feature']\n",
    "    dat = conversation['processed_data'][0]['label']\n",
    "    text_prepend = \"Experience Type: \"+ str(dat['experience_type'])+\", emotion type: \"+str(dat['emotion_type'])+\", problem type: \"+str(dat['problem_type'])+\", situation: \"+str(dat['situation'])+\", emotion intensity change: \"+str(dat['emotion_intensity_change'])+\" \"\n",
    "    conv_data = text_prepend + conv_data\n",
    "    chunks = splitter.split_text(conv_data)\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        embeddings.append(model.encode(chunk))\n",
    "    conversation_embeddings.append(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7592X_BW6i9",
    "outputId": "a5ca1ddd-24a7-40e8-afd4-c6bd006a9263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# Averaged the embeddings for all the chuncks in a conversation\n",
    "averaged_embeddings = []\n",
    "for conv in conversation_embeddings:\n",
    "    temp = np.array(conv)\n",
    "    averaged_embeddings.append(np.mean(temp,axis=0))\n",
    "\n",
    "print(len(averaged_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4ZNWrcQUWm5",
    "outputId": "8010e197-e85f-4982-e5a6-03cab1eb5886"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1jXURw0UWm5",
    "outputId": "21f93485-c996-4df6-8977-567e65ab9fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of the embeddings with the closest similarity are: 0 and 1\n",
      "The similarity score between the two closest embeddings is: 0.9183428883552551\n"
     ]
    }
   ],
   "source": [
    "embeddings_matrix = np.vstack(averaged_embeddings)\n",
    "\n",
    "# Compute the cosine similarity for every pair of embeddings in the matrix\n",
    "similarity_scores = cosine_similarity(embeddings_matrix)\n",
    "\n",
    "# Fill the diagonal with zero to exclude self-similarity from consideration\n",
    "np.fill_diagonal(similarity_scores, 0)\n",
    "\n",
    "# Find the indices of the maximum value in the similarity scores matrix\n",
    "# This will be the pair of embeddings that are most similar\n",
    "max_sim_index = np.unravel_index(np.argmax(similarity_scores), similarity_scores.shape)\n",
    "\n",
    "# The pair of instances with the closest embeddings\n",
    "embedding_1_index, embedding_2_index = max_sim_index\n",
    "closest_embeddings_pair = (averaged_embeddings[embedding_1_index], averaged_embeddings[embedding_2_index])\n",
    "\n",
    "print(f\"The indices of the embeddings with the closest similarity are: {embedding_1_index} and {embedding_2_index}\")\n",
    "print(f\"The similarity score between the two closest embeddings is: {similarity_scores[embedding_1_index, embedding_2_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wM2a6IZ6UWm5",
    "outputId": "54a04521-5cfe-4c83-e310-e4e933b4764e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:  always being asked to do things and help , and no one is here for me\n"
     ]
    }
   ],
   "source": [
    "print(\"Document 1: \", random_100_samples[embedding_1_index]['processed_data'][0]['label']['situation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Etff5O-ofsVq",
    "outputId": "e123e24b-3543-4651-e2e1-8103b56e2a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 2:  I have complete unsupportive friends its to the point where i dont even feel like i have friends any more .\n"
     ]
    }
   ],
   "source": [
    "print(\"Document 2: \",random_100_samples[embedding_2_index]['processed_data'][0]['label']['situation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8i_nMF1ZNSs"
   },
   "source": [
    "<a id=\"train-section\"></a>\n",
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHDucfVFUWm3",
    "outputId": "5312220f-5558-41ba-a4f7-863ce759bdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost for loading the whole dataset: 0.04702591896057129 seconds\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset = DatasetFormatter.load_dataset(converted_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RffDWVuuUWm3",
    "outputId": "d0447afc-31ba-43ea-b683-d12e487893e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data': '[{\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"Hello\\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Question\"}, \"content\": \"Hello, what would you like to talk about?\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"I am having a lot of anxiety about quitting my current job. It is too stressful but pays well\\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Question\"}, \"content\": \"What makes your job stressful for you?\"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"5\"}, \"content\": \"I have to deal with many people in hard financial situations and it is upsetting \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Question\"}, \"content\": \"Do you help your clients to make it to a better financial situation?\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"I do, but often they are not going to get back to what they want. Many people are going to lose their home when safeguards are lifted \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Affirmation and Reassurance\"}, \"content\": \"But you offer them a better future than what they have currently. It may not be what they wanted, but it helps them in the long run.\"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"5\"}, \"content\": \"That is true but sometimes I feel like I should put my feelings and health first \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Affirmation and Reassurance\"}, \"content\": \"I can understand that. \"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Question\"}, \"content\": \"Is there another job that would pay you close to what you currently make?\"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"5\"}, \"content\": \"Probably not. I was with the same company for a long time and I consistently get a bonus every year \"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Others\"}, \"content\": \"Is it possible to reframe how you look at your clients\\' dire financial situations?\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"I could try. It mostly gets to me at the end of the day \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Information\"}, \"content\": \"Some people can\\'t do what you do because they don\\'t have the heart to give someone else bad news. The reality is though, someone needs to fill that role and you do help people\"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"4\"}, \"content\": \"That is also true. Sometimes I wonder if it really is for me though  \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Self-disclosure\"}, \"content\": \"I\\'ve had to deal with collections before when I was in  bad financial condition. The person on the other line was really helpful though. She was understanding,\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Providing Suggestions\"}, \"content\": \"It may not be for you. I think you should think about the pros and cons of keeping your position. It might make things clearer for you. \"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"5\"}, \"content\": \"That is true. Maybe I just need to sit down and really think about it \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Restatement or Paraphrasing\"}, \"content\": \"I wouldn\\'t stay if it really impacts your mental health in a negative way. Still, you may need to zoom out and see the bigger picture: that you provide a needed service and you do it compassionately\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"It really is a big decision \\\\n\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"Thank you for the different perspective \\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Affirmation and Reassurance\"}, \"content\": \"No doubt, but you know in your heart what is right for you. \"}, {\"speaker\": \"seeker\", \"annotation\": {\"feedback\": \"4\"}, \"content\": \"That is true. Thanks again \\\\n\"}, {\"speaker\": \"seeker\", \"annotation\": {}, \"content\": \"Bye\\\\n\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Affirmation and Reassurance\"}, \"content\": \"It\\'s no problem. I hope you can make a decision about this situation and then be at peace with it\"}, {\"speaker\": \"supporter\", \"annotation\": {\"strategy\": \"Others\"}, \"content\": \"Ok, take care\"}]',\n",
       " 'processed_data': [{'feature': \"seeker: Hello. supporter: Hello, what would you like to talk about?. seeker: I am having a lot of anxiety about quitting my current job. It is too stressful but pays well. supporter: What makes your job stressful for you?. seeker: I have to deal with many people in hard financial situations and it is upsetting . supporter: Do you help your clients to make it to a better financial situation?. seeker: I do, but often they are not going to get back to what they want. Many people are going to lose their home when safeguards are lifted . supporter: But you offer them a better future than what they have currently. It may not be what they wanted, but it helps them in the long run.. seeker: That is true but sometimes I feel like I should put my feelings and health first . supporter: I can understand that. supporter: Is there another job that would pay you close to what you currently make?. seeker: Probably not. I was with the same company for a long time and I consistently get a bonus every year . supporter: Is it possible to reframe how you look at your clients' dire financial situations?. seeker: I could try. It mostly gets to me at the end of the day . supporter: Some people can't do what you do because they don't have the heart to give someone else bad news. The reality is though, someone needs to fill that role and you do help people. seeker: That is also true. Sometimes I wonder if it really is for me though  . supporter: I've had to deal with collections before when I was in  bad financial condition. The person on the other line was really helpful though. She was understanding,. supporter: It may not be for you. I think you should think about the pros and cons of keeping your position. It might make things clearer for you. seeker: That is true. Maybe I just need to sit down and really think about it . supporter: I wouldn't stay if it really impacts your mental health in a negative way. Still, you may need to zoom out and see the bigger picture: that you provide a needed service and you do it compassionately. seeker: It really is a big decision . seeker: Thank you for the different perspective . supporter: No doubt, but you know in your heart what is right for you. seeker: That is true. Thanks again . seeker: Bye. supporter: It's no problem. I hope you can make a decision about this situation and then be at peace with it. supporter: Ok, take care. \",\n",
       "   'label': {'experience_type': 'Previous Experience',\n",
       "    'emotion_type': 'anxiety',\n",
       "    'problem_type': 'job crisis',\n",
       "    'situation': 'I hate my job but I am scared to quit and seek a new career.',\n",
       "    'emotion_intensity_change': 2}}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vpGMwbZ4lARk"
   },
   "outputs": [],
   "source": [
    "## Used a subset of the dataset since the dataset is unbalanced.\n",
    "texts = []\n",
    "word_labels = []\n",
    "\n",
    "for i in loaded_dataset:\n",
    "    if i[\"processed_data\"][0][\"label\"][\"emotion_type\"] == \"anxiety\" or i[\"processed_data\"][0][\"label\"][\"emotion_type\"] == \"depression\":\n",
    "        texts.append(i[\"processed_data\"][0][\"feature\"])\n",
    "        word_labels.append(i[\"processed_data\"][0][\"label\"][\"emotion_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "I_xtz6HNk2xP"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(word_labels)\n",
    "num_labels = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-DSgJfoHtx6U"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': texts, 'label': encoded_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3fyHnuZsw3Ez"
   },
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "tMz8sDo2DHBa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "L6OQkBDFDHD1"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "MODEL_PARAMS = {\n",
    "    \"batch_size\": 8,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": 5,\n",
    "    \"chunk_size\": 510,\n",
    "    \"stride\": 510,\n",
    "    \"minimal_chunk_length\": 510,\n",
    "    \"pooling_strategy\": \"mean\",\n",
    "}\n",
    "model = BertClassifierWithPooling(**MODEL_PARAMS, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRJtV8XkkPAT",
    "outputId": "0b9e615f-5822-4385-fc90-ae12b7708025"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(0.7134, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4200, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.8674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5383, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7100, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6600, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7883, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7147, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6323, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6945, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7144, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7223, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7141, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6783, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7023, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6716, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7007, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6914, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6895, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6868, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6795, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7221, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6912, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6878, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6979, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6887, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6761, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7006, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6838, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6860, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7018, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6960, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6719, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7435, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7240, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6694, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6885, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7070, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7042, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6867, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6961, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch:  0\n",
      "Loss:  tensor(0.7139, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6937, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6931, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6974, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7040, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6755, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6848, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6882, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6932, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6893, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6748, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6764, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6723, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6814, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6785, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6955, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6502, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6258, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6616, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6903, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7126, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6954, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6218, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6073, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6479, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9551, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5638, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7116, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7491, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7699, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5689, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6349, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6744, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7244, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5493, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5498, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.8470, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6140, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9902, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6450, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6837, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6970, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6586, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6651, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6632, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7318, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6233, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6702, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7117, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6829, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch:  1\n",
      "Loss:  tensor(0.6410, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4113, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5884, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5186, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5688, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5596, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6052, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3210, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4388, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7108, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5355, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3094, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4544, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6597, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4430, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3296, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4650, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6045, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3982, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7133, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3968, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3986, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4608, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7806, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4389, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2798, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3444, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.8754, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7024, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5555, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5905, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5965, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6344, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4131, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4877, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(1.0465, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4859, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5910, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6159, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5746, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4756, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7486, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6606, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5628, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4074, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6295, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3507, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch:  2\n",
      "Loss:  tensor(0.2161, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9797, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4360, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5276, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2994, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4686, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4623, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4653, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6918, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6522, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4253, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3163, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4148, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3330, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2677, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4167, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2832, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4054, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0978, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3282, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.7190, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3999, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1580, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(1.1573, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3538, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9128, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2265, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5521, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6058, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1781, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6679, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5518, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4603, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3657, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5205, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5847, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4873, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5338, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3508, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2348, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2825, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4595, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.9346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2207, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1589, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1682, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5527, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2192, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2550, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0934, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch:  3\n",
      "Loss:  tensor(0.2165, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0790, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2922, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3843, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1862, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0322, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4366, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3505, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1930, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.6044, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3786, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1757, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1300, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3082, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4293, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1050, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1714, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3257, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1164, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1475, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2590, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2985, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1291, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0213, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2234, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1503, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1320, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2514, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0245, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0342, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0075, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0264, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5710, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0674, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3811, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0102, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3531, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0066, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2880, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.4809, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0219, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5487, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0199, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5259, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3260, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0217, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1437, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0813, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5658, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3539, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1736, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.2099, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1733, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3198, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.3010, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.5637, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.1941, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Loss:  tensor(0.0452, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "Epoch:  4\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=5)  #  Warning about tokeninizing too long text is expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ufLH9_hhkO5z"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YEaxYnbkkOwE",
    "outputId": "67a3b8c7-98c1-415b-8c17-c7a32a2f32e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 81.64251207729468%\n"
     ]
    }
   ],
   "source": [
    "# Calculate model accuracy on the test data\n",
    "accurate = sum(preds == np.array(y_test).astype(bool))\n",
    "accuracy = accurate / len(y_test)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBEPord-DIX6"
   },
   "source": [
    "The better approach would be using Dynamic RNNs to take into account the temporal nature of the chunk embeddings received from the BERT model. This can potentially help improve the performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALom-2nT0d8M"
   },
   "source": [
    "<a id=\"refer-section\"></a>\n",
    "## References\n",
    "\n",
    "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "https://github.com/mim-solutions/bert_for_longer_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "PUqAfSra0s1d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
